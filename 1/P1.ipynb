{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Assignment #1\n",
    "## Ali Hamzehpour 810100129\n",
    "## Implementation of Informed and Uninformed Search Algorithms and Solving a Problem with Them.\n",
    "### Problem Description\n",
    "We have a graph which each node contains either a student or a pizza station or nothing. Each student wants to have pizza from a unique pizza station and our task is to find the shortest path to deliver all pizzas to the students. we have some limitations: some edges in graph are shaky which means after we use them, we can't use them for some seconds. Also we only can carry one pizza at one time and some students' pizzas should be delivered sooner than some others. We have to implement BFS, IDS and A* algorithms and solve the problem with each of them."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Modeling\n",
    "For modeling the problem's graph, First I implemented ```Edge``` and ```Node``` classes. ```Edge``` contains two nodes and a delay time if it's shaky. (otherwise it's set as ```None```) ```Node``` contains all of its edges and if the node has a pizza station or a student, it will have a delivery id as well (if student A wants to have pizza from station B, both of these nodes will have the same delivery id). Then I implemented a ```Graph``` class which contains all of the nodes and edges in our problem and it will hold order priorities as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum, auto\n",
    "from dataclasses import dataclass\n",
    "\n",
    "class EdgeType(Enum):\n",
    "    NORMAL = auto()\n",
    "    SHAKY = auto()\n",
    "    \n",
    "class NodeType(Enum):\n",
    "    NORMAL = auto()\n",
    "    PIZZA = auto()\n",
    "    STUDENT = auto()    \n",
    "    \n",
    "@dataclass\n",
    "class Edge:\n",
    "    id: int\n",
    "    type: EdgeType\n",
    "    nodes: tuple[int, int]\n",
    "    delay: int\n",
    "    \n",
    "    def find_dst(self, origin: int) -> int:\n",
    "        if origin == self.nodes[0]:\n",
    "            return self.nodes[1]\n",
    "        return self.nodes[0]\n",
    "    \n",
    "@dataclass\n",
    "class Node:\n",
    "    id: int\n",
    "    type: NodeType\n",
    "    delivery_id: int\n",
    "    edges: list[Edge]\n",
    "    \n",
    "def make_normal_node(id: int) -> Node:\n",
    "    return Node(id, NodeType.NORMAL, None, [])\n",
    "\n",
    "def make_normal_edge(id: int, n1: int, n2: int) -> Edge:\n",
    "    return Edge(id, EdgeType.NORMAL, (n1, n2), None)\n",
    "    \n",
    "class Graph:\n",
    "    def __init__(self, num_of_nodes: int):\n",
    "        self.nodes: list[Node] = [make_normal_node(i) for i in range(1, num_of_nodes + 1)]\n",
    "        self.edges: list[Edge] = []\n",
    "        self.shaky_edges: list[Edge] = []\n",
    "        self.num_of_deliveries = 0\n",
    "        self.priorities: list[tuple(int, int)] = []\n",
    "        \n",
    "    def add_edge(self, n1: int , n2: int) -> None:\n",
    "        new_edge: Edge = make_normal_edge(len(self.edges) + 1, n1, n2)\n",
    "        self.edges.append(new_edge)\n",
    "        self.nodes[n1 - 1].edges.append(new_edge)\n",
    "        self.nodes[n2 - 1].edges.append(new_edge)\n",
    "    \n",
    "    def set_as_shaky(self, edge_id: int, delay: int) -> None:\n",
    "        edge: Edge = self.edges[edge_id - 1]\n",
    "        edge.type = EdgeType.SHAKY\n",
    "        edge.delay = delay\n",
    "        self.shaky_edges.append(edge)\n",
    "    \n",
    "    def set_delivery(self, std_node_id: int, pizza_node_id: int) -> None:\n",
    "        self.num_of_deliveries += 1\n",
    "        pizza_node: Node = self.nodes[pizza_node_id - 1]\n",
    "        pizza_node.type = NodeType.PIZZA\n",
    "        pizza_node.delivery_id = self.num_of_deliveries\n",
    "        std_node: Node = self.nodes[std_node_id - 1]\n",
    "        std_node.type = NodeType.STUDENT\n",
    "        std_node.delivery_id = self.num_of_deliveries\n",
    "        \n",
    "    def add_priority(self, std1: int, std2: int) -> None:\n",
    "        self.priorities.append((std1, std2))\n",
    "                \n",
    "    def get_node(self, node_id: int) -> Node:\n",
    "        return self.nodes[node_id - 1]   \n",
    "     "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem States\n",
    "These attributes make two states different from each other:\n",
    "* ```cur_node_id``` -> current node id which we are in the graph.\n",
    "* ```cur_pizza``` -> current pizza we are carrying.\n",
    "* ```handled_deliveries``` -> a set of delivery ids that are delivered.\n",
    "* ```shaky_adj_edges``` -> the remaining time we should wait to use each edge that contains the current node which we are in.\n",
    "<br>\n",
    " \n",
    "States also have other attributes:\n",
    "* ```shaky_edges_remain_time``` -> the remaining time of all the shaky edges\n",
    "* ```cur_path``` -> the path to the current node\n",
    "<br>\n",
    "\n",
    "A goal state is a state that has delivered all the deliveries. The initial state is the state with the node id of the starting node and all other attributes are either 0, empty or None. ```find_next_state``` function will return all of the possible next states of the current state. I did some optimizations for these function: If we have stayed for some shaky edges we will use only those shaky edges for the next state and also we only stay on a node that has a shaky edge.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Callable\n",
    "from __future__ import annotations\n",
    "\n",
    "class State:\n",
    "    def __init__(self, cur_node_id: int , cur_pizza: int, handled_deliveries: set[int],\n",
    "               shaky_edges_remain_time: dict[int, int], cur_path: list[int], graph: Graph):\n",
    "        self.cur_node_id = cur_node_id\n",
    "        self.cur_pizza = cur_pizza\n",
    "        self.handled_deliveries = handled_deliveries\n",
    "        self.shaky_edges_remain_time = shaky_edges_remain_time\n",
    "        self.cur_path = cur_path\n",
    "        self.shaky_adj_edges: dict[int, int] = self.find_shaky_adj_edges(graph)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"{self.cur_node_id} {self.cur_pizza} {self.handled_deliveries} {self.shaky_adj_edges}\"\n",
    "    \n",
    "    def __eq__(self, other: Any) -> bool:\n",
    "        return (isinstance(other, State) and\n",
    "               self.cur_node_id == other.cur_node_id and\n",
    "               self.cur_pizza == other.cur_pizza and\n",
    "               self.handled_deliveries == other.handled_deliveries and\n",
    "               self.shaky_adj_edges == other.shaky_adj_edges)\n",
    "    \n",
    "    def __hash__(self) -> int:\n",
    "        return hash(str(self))\n",
    "\n",
    "    def find_shaky_adj_edges(self, graph: Graph) -> tuple[int, int]:\n",
    "        cur_node: Node = graph.get_node(self.cur_node_id)\n",
    "        shaky_adj_edges = {}\n",
    "        for edge in cur_node.edges:\n",
    "            if edge.type == EdgeType.SHAKY:\n",
    "                shaky_adj_edges[edge.id] = self.shaky_edges_remain_time[edge.id]\n",
    "        return shaky_adj_edges\n",
    "\n",
    "    def is_goal(self, total_deliveries: int) -> bool:\n",
    "        return total_deliveries == len(self.handled_deliveries)\n",
    "\n",
    "    def can_use_edge(self, edge: Edge) -> bool:\n",
    "        return not(edge.type == EdgeType.SHAKY and self.shaky_adj_edges[edge.id] > 0)\n",
    "    \n",
    "    def is_stay_state(self) -> bool:\n",
    "        return len(self.cur_path) > 1 and self.cur_path[-2] == self.cur_node_id\n",
    "    \n",
    "    def get_stay_state(self, updated_remain_time: dict[int, int], graph: Graph) -> State:\n",
    "        return State(self.cur_node_id, self.cur_pizza, self.handled_deliveries.copy(), \n",
    "                    updated_remain_time.copy(), self.cur_path + [self.cur_node_id], graph)\n",
    "        \n",
    "    def calc_new_remain_time(self) -> dict[int, int]:\n",
    "        updated_remain_time = self.shaky_edges_remain_time.copy()\n",
    "        for shaky_edge in updated_remain_time:\n",
    "            updated_remain_time[shaky_edge] = max(updated_remain_time[shaky_edge] - 1, 0) \n",
    "        return updated_remain_time\n",
    "    \n",
    "    def check_priority(self, delivery_id: int, graph: Graph) -> bool:\n",
    "        priorities: list[tuple[int, int]] = graph.priorities\n",
    "        for std1, std2 in priorities:\n",
    "            if std2 == delivery_id and std1 not in self.handled_deliveries:\n",
    "                return False\n",
    "        return True     \n",
    "    \n",
    "    def find_states_of_new_position(self, dst: Node, edge: Edge, graph: Graph,\n",
    "                                    updated_remain_time: dict[int, int]) -> list[State]:\n",
    "        next_states: list[State] = []\n",
    "        updated_remain_time_copy = updated_remain_time.copy()\n",
    "        new_handled_deliveries = self.handled_deliveries.copy()\n",
    "        new_pizza = self.cur_pizza\n",
    "        if edge.type == EdgeType.SHAKY:\n",
    "            updated_remain_time_copy[edge.id] = edge.delay\n",
    "        if dst.type == NodeType.STUDENT:\n",
    "            if dst.delivery_id == self.cur_pizza:\n",
    "                new_handled_deliveries.add(self.cur_pizza)\n",
    "                new_pizza = None\n",
    "        elif dst.type == NodeType.PIZZA:\n",
    "            if self.cur_pizza == None and self.check_priority(dst.delivery_id, graph):\n",
    "                next_states.append(State(dst.id, dst.delivery_id, new_handled_deliveries, \n",
    "                    updated_remain_time.copy(), self.cur_path + [dst.id], graph))\n",
    "        next_states.append(State(dst.id, new_pizza, new_handled_deliveries, \n",
    "                                    updated_remain_time_copy, self.cur_path + [dst.id], graph))\n",
    "        return next_states\n",
    "\n",
    "    def find_next_states(self, graph: Graph) -> list[State]:\n",
    "        updated_remain_time: dict[int, int] = self.calc_new_remain_time()\n",
    "        next_states: list[State] = []\n",
    "        cur_node: Node = graph.get_node(self.cur_node_id)\n",
    "        used_stay_state = False\n",
    "        for edge in cur_node.edges:\n",
    "            if self.is_stay_state() and edge.type != EdgeType.SHAKY:\n",
    "                continue\n",
    "            elif self.can_use_edge(edge):\n",
    "                dst_id: int = edge.find_dst(self.cur_node_id)\n",
    "                dst: Node = graph.get_node(dst_id)\n",
    "                next_states.extend(self.find_states_of_new_position(dst, edge, graph, updated_remain_time.copy()))\n",
    "            elif not used_stay_state:\n",
    "                next_states.append(self.get_stay_state(updated_remain_time, graph))\n",
    "        return next_states\n",
    "    \n",
    "def make_starting_state(starting_node_id: int, graph: Graph) -> State:\n",
    "    shaky_edges_remain_time = {edge.id: 0 for edge in graph.shaky_edges} \n",
    "    return State(starting_node_id, None, set(),\n",
    "                 shaky_edges_remain_time, [starting_node_id], graph)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breadth First Search\n",
    "BFS first checks states that are closer to starting state. It'll always return the optimal path because between each state is one second difference. ```frontier``` is the queue of states. I add each state to ```explored``` set when I add them to ```frontier``` because ```explored``` is a set and it's faster to do all the search (to check if we've visited a state before or not) in it. The goal check is also done when we're adding a state to the ```frontier``` and not when a state comes on top of ```frontier```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BFS(starting_state: State, graph: Graph) -> tuple[State, int]:\n",
    "    frontier: list[State] = [starting_state]\n",
    "    explored: set[State] = set([starting_state])\n",
    "    while frontier:\n",
    "        cur_state = frontier.pop(0)\n",
    "        next_states = cur_state.find_next_states(graph)\n",
    "        for ns in next_states:\n",
    "            if ns.is_goal(graph.num_of_deliveries):\n",
    "                return ns, len(explored)\n",
    "            if ns in explored: \n",
    "                continue\n",
    "            frontier.append(ns)\n",
    "            explored.add(ns)\n",
    "    return None, len(explored)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterative Deepening Search\n",
    "IDS runs DFS in the states' graph but with depth limit. the depth limit starts from 0 and increases until we find the goal. Because of this method, IDS works like BFS and always finds the optimal path. The difference is in the memory. IDS only saves the states in our current path so it takes less memory than BFS. I implemented IDS in two ways. one recursively(```recursive_IDS```) and other with stack. (```stack_IDS```)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_IDS(starting_state: State, graph: Graph) -> (State, int):\n",
    "    def IDS_helper(cur_state: State, explored: set[State], limit: int, num_of_explored: int) -> (State, int):\n",
    "        num_of_explored += 1\n",
    "        if limit == 0:\n",
    "            return None, num_of_explored\n",
    "        next_states: list[State] = cur_state.find_next_states(graph)\n",
    "        new_explored: set[State] = explored.copy()\n",
    "        new_states: list[State] = []\n",
    "        for ns in next_states:\n",
    "            if ns.is_goal(graph.num_of_deliveries):\n",
    "                return ns, num_of_explored\n",
    "            if ns in explored or limit == 1:\n",
    "                continue\n",
    "            new_explored.add(ns)\n",
    "            new_states.append(ns)\n",
    "        for ns in new_states:\n",
    "            result, num_of_explored = IDS_helper(ns, new_explored, limit - 1, num_of_explored)\n",
    "            if result:\n",
    "                return result, num_of_explored\n",
    "        return None, num_of_explored\n",
    "    explored: set[State] = set()\n",
    "    num_of_explored: int = 0\n",
    "    depth_limit: int = 0\n",
    "    MAX_LIMIT: int = 100\n",
    "    while depth_limit < MAX_LIMIT:\n",
    "        result, num_of_explored = IDS_helper(starting_state, explored, depth_limit, num_of_explored)\n",
    "        if result:\n",
    "            return result, num_of_explored\n",
    "        depth_limit += 1\n",
    "        explored = set()\n",
    "    return None, num_of_explored\n",
    "\n",
    "def stack_IDS(starting_state: State, graph: Graph) -> (State, int):\n",
    "    depth_limit: int = 1\n",
    "    MAX_DEPTH: int = 50\n",
    "    num_of_explored: int = 0\n",
    "    while depth_limit < MAX_DEPTH:\n",
    "        frontier: list[tuple[State, int]] = [(starting_state, 0)]\n",
    "        explored_sets: list[set[State]] = [set([starting_state])]\n",
    "        while frontier:\n",
    "            num_of_explored += 1\n",
    "            cur_state, cur_depth = frontier.pop()\n",
    "            cur_explored = explored_sets.pop()\n",
    "            next_states = cur_state.find_next_states(graph)\n",
    "            new_states = []\n",
    "            for ns in next_states:\n",
    "                if ns.is_goal(graph.num_of_deliveries):\n",
    "                    return ns, num_of_explored\n",
    "                if cur_depth == depth_limit - 1:\n",
    "                    continue\n",
    "                if ns in cur_explored:\n",
    "                    continue\n",
    "                cur_explored.add(ns)\n",
    "                new_states.append(ns)\n",
    "            for ns in new_states:\n",
    "                frontier.append((ns, cur_depth + 1))\n",
    "                explored_sets.append(cur_explored.copy())   \n",
    "        depth_limit += 1\n",
    "    return None, num_of_explored\n",
    "        \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A*\n",
    "A* is like BFS but we check states that has better estimated cost value. estimated cost value is the sum of current cost until the state and a heuristic function. heuristic function estimates how many seconds is remained until the goal state. A heuristic function is admissible if $$h(State1) \\leq cost(State1toGoal)  $$and heuristic function is called consistent if $$ h(State1) - h(State2) \\leq realcost(State1 to State2)$$\n",
    "If a heuristic is admissible, the solution will be optimal in tree search and if a heuristic is consistent, the solution will be optimal in graph search.\n",
    "the heuristic I use for this problem is:\n",
    "* if we are carryig a pizza:\n",
    "$$ h(state) = 2 \\times (NumberOfAllDeliveries - NumberOfHandledDeliveries) - 1$$\n",
    "* if not:\n",
    "$$ h(state) = 2 \\times (NumberOfAllDeliveries - NumberOfHandledDeliveries)$$\n",
    "The logic behind it is that we need at least 2 steps for each delivery: one to reach the pizza station and the other to reach the student's node and if we already have a pizza, we'll decrease one step. So the heuristic is admissible. It's also consistent because for each step the heuristic increases at most one value(If we deliver a pizza in that step or get a pizza from station)but in reality each step takes one second so the heuristic between two states is always less than or equal to the real cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_heuristic(state: State, graph: Graph) -> int:\n",
    "    has_pizza: int = 0\n",
    "    if state.cur_pizza:\n",
    "        has_pizza = 1\n",
    "    return 2 * (graph.num_of_deliveries - len(state.handled_deliveries)) - has_pizza"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I created a wrapper class for python's ```heapq``` library because it didn't have the option to use a custom compare function and also it wasn't object-oriented. ```MinHeap``` class takes some initial values for heap and a key function for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "class MinHeap:\n",
    "    def __init__(self, initial: list[Any] = None, key: Callable[[Any], int] = lambda x :x):\n",
    "        self.key = key\n",
    "        if initial:\n",
    "            self._data = [[key(item), i, item] for i, item in enumerate(initial)]\n",
    "            self.index = len(self._data)\n",
    "            heapq.heapify(self._data)\n",
    "        else:\n",
    "            self._data = []\n",
    "\n",
    "    def push(self, item):\n",
    "        heapq.heappush(self._data, [self.key(item), self.index, item])\n",
    "        self.index += 1\n",
    "\n",
    "    def pop(self):\n",
    "        return heapq.heappop(self._data)[-1]\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for i in self._data:\n",
    "            yield i[-1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implementation of A* is the same as BFS but ```frontier``` is a min-heap which every time we pop the state with lowest estimated cost. The function also has ```alpha``` parameter which is for weighted A*. Weighted A* is the same as normal A* but we multiply heuristic value with the constant value $\\alpha$. It makes the search faster but it could lose its optimality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def A_star(starting_state: State, graph: Graph, alpha: int = 1) -> tuple[State, int]:\n",
    "    \n",
    "    def estimate_cost(state: State) -> int:\n",
    "        return alpha * calc_heuristic(state, graph) + len(state.cur_path)\n",
    "    \n",
    "    frontier: MinHeap = MinHeap([starting_state], estimate_cost)\n",
    "    explored: set[State] = set([starting_state])\n",
    "    while frontier:\n",
    "        cur_state = frontier.pop()\n",
    "        next_states = cur_state.find_next_states(graph)\n",
    "        for ns in next_states:\n",
    "            if ns.is_goal(graph.num_of_deliveries):\n",
    "                return ns, len(explored)\n",
    "            if ns in explored:\n",
    "                continue\n",
    "            frontier.push(ns)\n",
    "            explored.add(ns)\n",
    "    return None, len(explored)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```read_input``` is a function that simply reads input from a file and saves it in a graph class and returns it with the id of the node in which we should start our search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_input(input_file_name: str) -> (Graph, int):\n",
    "    input_file = open(input_file_name, \"r\")\n",
    "    n, m = map(int, input_file.readline().split())\n",
    "    graph = Graph(n)\n",
    "    for i in range(m):\n",
    "        n1, n2 = map(int, input_file.readline().split())\n",
    "        graph.add_edge(n1, n2)\n",
    "    h = int(input_file.readline())\n",
    "    for i in range(h):\n",
    "        edge_id, delay = map(int, input_file.readline().split())\n",
    "        graph.set_as_shaky(edge_id, delay)\n",
    "    starting_node_id = int(input_file.readline())\n",
    "    s = int(input_file.readline())\n",
    "    for i in range(s):\n",
    "        std_node, pizza_node = map(int, input_file.readline().split())\n",
    "        graph.set_delivery(std_node, pizza_node)\n",
    "    t = int(input_file.readline())\n",
    "    for i in range(t):\n",
    "        s1, s2 = map(int, input_file.readline().split())\n",
    "        graph.add_priority(s1, s2)\n",
    "    return (graph, starting_node_id)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```test_search_func``` is a wrapper function which takes a search function and does the search in the graph using it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def test_search_func(search_func: Callable[[State, Graph], Tuple[State, int]],\n",
    "                     starting_state: State, graph: Graph) -> None:\n",
    "    REPEAT: int = 3\n",
    "    time_sum: int = 0\n",
    "    for i in range(REPEAT):\n",
    "        start: int = time.time()\n",
    "        goal_state, explored_nodes = search_func(starting_state, graph)\n",
    "        end: int = time.time()\n",
    "        time_sum += (end - start)\n",
    "    print(\"Average time spent: \", time_sum / REPEAT)\n",
    "    print(\"Found path:\", end = \" \")\n",
    "    print(*goal_state.cur_path, sep=\"->\")\n",
    "    print(\"Length of found path: \", len(goal_state.cur_path))        \n",
    "    print(\"Number of explored nodes: \", explored_nodes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "for each test I did the search with all of the algorithms: (Because IDS algorithm took too long I tested it in separate cells.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "algorithms ={\"BFS\": BFS,\n",
    "              \"A*\": partial(A_star, alpha = 1),\n",
    "              \"A* with alpha = 2\": partial(A_star, alpha = 2),\n",
    "              \"A* with alpha = 4\": partial(A_star, alpha = 4),\n",
    "          #    \"IDS\": IDS\n",
    "            }\n",
    "def run_test(test_number: int)-> None:\n",
    "    print(f\"TEST{test_number}: \")\n",
    "    input_file_name = f\"./tests/Test{test_number}.txt\"\n",
    "    graph, starting_node_id = read_input(input_file_name)\n",
    "    starting_state = make_starting_state(starting_node_id, graph)\n",
    "    for alg in algorithms:\n",
    "        print(f\"{alg}: \")\n",
    "        alg_func = algorithms[alg]\n",
    "        test_search_func(alg_func, starting_state, graph)\n",
    "        print(\"######\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST1: \n",
      "BFS: \n",
      "Average time spent:  0.012333552042643229\n",
      "Found path: 6->4->10->5->3->8->9->1->7->9->2\n",
      "Length of found path:  11\n",
      "Number of explored nodes:  613\n",
      "######\n",
      "A*: \n",
      "Average time spent:  0.005999962488810222\n",
      "Found path: 6->4->10->9->1->3->8->9->7->9->2\n",
      "Length of found path:  11\n",
      "Number of explored nodes:  390\n",
      "######\n",
      "A* with alpha = 2: \n",
      "Average time spent:  0.0010066032409667969\n",
      "Found path: 6->4->10->9->1->3->8->9->7->9->2\n",
      "Length of found path:  11\n",
      "Number of explored nodes:  102\n",
      "######\n",
      "A* with alpha = 4: \n",
      "Average time spent:  0.001011212666829427\n",
      "Found path: 6->4->10->9->1->3->8->9->7->9->2\n",
      "Length of found path:  11\n",
      "Number of explored nodes:  103\n",
      "######\n"
     ]
    }
   ],
   "source": [
    "run_test(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For IDS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDS recursive TEST1:\n",
      "Average time spent:  0.25533318519592285\n",
      "Found path: 6->4->10->5->3->8->9->1->7->9->2\n",
      "Length of found path:  11\n",
      "Number of explored nodes:  12704\n",
      "IDS non-recursive TEST1:\n",
      "Average time spent:  0.2690231005350749\n",
      "Found path: 6->4->10->9->7->9->2->9->1->3->8\n",
      "Length of found path:  11\n",
      "Number of explored nodes:  12742\n"
     ]
    }
   ],
   "source": [
    "print(\"IDS recursive TEST1:\")\n",
    "INPUT_FILE = \"./tests/Test1.txt\"\n",
    "graph, starting_node_id = read_input(INPUT_FILE)\n",
    "starting_state = make_starting_state(starting_node_id, graph)\n",
    "test_search_func(recursive_IDS, starting_state, graph)\n",
    "print(\"IDS non-recursive TEST1:\")\n",
    "test_search_func(stack_IDS, starting_state, graph)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Alg | found path length | explored nodes | Run Time |\n",
    "| :-: | :----------------:| :------------: | :------: |\n",
    "| BFS | 11    | 613                        | 0.010689179102579752  |\n",
    "| IDS recursive |    11   |            12704                |     0.24799895286560059     |\n",
    "| IDS non-recursive |    11   |        12742                    |     0.2346787452697754     |\n",
    "| A*  | 11    | 390                         | 0.008892695109049479   |\n",
    "| A* Alpha=2  | 11         | 102                   | 0.0009995301564534504   |\n",
    "| A* Alpha=4  | 11         | 103                  | 0.0010000069936116536   |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST2: \n",
      "BFS: \n",
      "Average time spent:  0.10967294375101726\n",
      "Found path: 14->9->4->15->12->3->12->6->14->1->14->12->3->8->6->4->10->11->8->3->13\n",
      "Length of found path:  21\n",
      "Number of explored nodes:  3599\n",
      "######\n",
      "A*: \n",
      "Average time spent:  0.0690005620320638\n",
      "Found path: 14->9->4->15->12->3->12->6->14->1->14->12->3->8->6->4->10->11->8->3->13\n",
      "Length of found path:  21\n",
      "Number of explored nodes:  3213\n",
      "######\n",
      "A* with alpha = 2: \n",
      "Average time spent:  0.038999716440836586\n",
      "Found path: 14->9->4->15->12->3->12->6->8->6->4->9->14->1->14->12->3->8->11->8->3->13\n",
      "Length of found path:  22\n",
      "Number of explored nodes:  1794\n",
      "######\n",
      "A* with alpha = 4: \n",
      "Average time spent:  0.009000142415364584\n",
      "Found path: 14->9->4->15->12->3->12->6->8->6->4->9->14->1->14->12->3->8->11->8->3->13\n",
      "Length of found path:  22\n",
      "Number of explored nodes:  558\n",
      "######\n"
     ]
    }
   ],
   "source": [
    " run_test(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For IDS it took too long to respond, in fact it checks about 90 million states when it reaches 20th depth! The reason is because we only keep our current path in explored set, we may see the same states in different path in our states' graph and it makes IDS to check too many states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"IDS recursive TEST2:\")\n",
    "# INPUT_FILE = \"./tests/Test2.txt\"\n",
    "# graph, starting_node_id = read_input(INPUT_FILE)\n",
    "# starting_state = make_starting_state(starting_node_id, graph)\n",
    "# test_search_func(recursive_IDS, starting_state, graph)\n",
    "# print(\"IDS non-recursive TEST2:\")\n",
    "# test_search_func(stack_IDS, starting_state, graph)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Alg | found path length | explored nodes | Run Time |\n",
    "| :-: | :----------------:| :------------: | :------: |\n",
    "| BFS | 21    | 3599                        | 0.0766916275024414  |\n",
    "| IDS |       |                            |          |\n",
    "| A*  | 21    | 3213                         | 0.0667714277903239   |\n",
    "| A* Alpha=2  | 22         | 1794                   | 0.04497575759887695   |\n",
    "| A* Alpha=4  | 22         | 558                  | 0.009969711303710938   |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST3: \n",
      "BFS: \n",
      "Average time spent:  1.9303345680236816\n",
      "Found path: 15->14->8->20->13->8->18->10->8->9->16->5->15->12->3->19->11->19->13->6->13->1->13->8->17->8->18->2->18->4->14->16\n",
      "Length of found path:  32\n",
      "Number of explored nodes:  53972\n",
      "######\n",
      "A*: \n",
      "Average time spent:  1.7310007413228352\n",
      "Found path: 15->14->8->20->13->8->18->10->8->9->16->5->15->12->3->19->11->19->13->6->13->1->13->8->17->8->18->2->18->4->14->16\n",
      "Length of found path:  32\n",
      "Number of explored nodes:  50331\n",
      "######\n",
      "A* with alpha = 2: \n",
      "Average time spent:  0.1600064436594645\n",
      "Found path: 15->14->8->20->13->8->18->10->8->9->16->5->15->12->3->19->11->19->13->6->13->1->13->8->17->8->18->2->18->4->14->16\n",
      "Length of found path:  32\n",
      "Number of explored nodes:  7417\n",
      "######\n",
      "A* with alpha = 4: \n",
      "Average time spent:  0.015660206476847332\n",
      "Found path: 15->14->8->20->8->18->2->18->10->8->9->16->5->15->12->3->19->13->8->18->4->14->16->14->4->1->13->8->17->19->11->19->13->6\n",
      "Length of found path:  34\n",
      "Number of explored nodes:  858\n",
      "######\n"
     ]
    }
   ],
   "source": [
    "run_test(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this test IDS was unable to find the answer in a normal time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"IDS recursive TEST3:\")\n",
    "# INPUT_FILE = \"./tests/Test3.txt\"\n",
    "# graph, starting_node_id = read_input(INPUT_FILE)\n",
    "# starting_state = make_starting_state(starting_node_id, graph)\n",
    "# test_search_func(recursive_IDS, starting_state, graph)\n",
    "# print(\"IDS non-recursive TEST2:\")\n",
    "# test_search_func(stack_IDS, starting_state, graph)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Alg | found path length | explored nodes | Run Time |\n",
    "| :-: | :----------------:| :------------: | :------: |\n",
    "| BFS | 32    | 53972                        | 1.79891037940979  |\n",
    "| IDS |       |                            |          |\n",
    "| A*  | 32    | 50331                         | 1.571475585301717   |\n",
    "| A* Alpha=2  | 32         | 7417                   | 0.17083978652954102   |\n",
    "| A* Alpha=4  | 34         | 858                  | 0.01749420166015625   |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing with additional tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST0: \n",
      "BFS: \n",
      "Average time spent:  0.0003333886464436849\n",
      "Found path: 1->2->3->4->4->4->3->2->3->5\n",
      "Length of found path:  10\n",
      "Number of explored nodes:  30\n",
      "######\n",
      "A*: \n",
      "Average time spent:  0.00033362706502278644\n",
      "Found path: 1->2->3->4->4->4->3->2->3->5\n",
      "Length of found path:  10\n",
      "Number of explored nodes:  29\n",
      "######\n",
      "A* with alpha = 2: \n",
      "Average time spent:  0.00033322970072428387\n",
      "Found path: 1->2->3->4->4->4->3->2->3->5\n",
      "Length of found path:  10\n",
      "Number of explored nodes:  24\n",
      "######\n",
      "A* with alpha = 4: \n",
      "Average time spent:  0.0003333091735839844\n",
      "Found path: 1->2->3->4->4->4->3->2->3->5\n",
      "Length of found path:  10\n",
      "Number of explored nodes:  21\n",
      "######\n"
     ]
    }
   ],
   "source": [
    "run_test(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST4: \n",
      "BFS: \n",
      "Average time spent:  0.016669511795043945\n",
      "Found path: 5->7->2->9->4->8->10->3->8->1->6->2\n",
      "Length of found path:  12\n",
      "Number of explored nodes:  731\n",
      "######\n",
      "A*: \n",
      "Average time spent:  0.009999752044677734\n",
      "Found path: 5->7->2->9->4->8->10->3->8->1->6->2\n",
      "Length of found path:  12\n",
      "Number of explored nodes:  548\n",
      "######\n",
      "A* with alpha = 2: \n",
      "Average time spent:  0.0016668637593587239\n",
      "Found path: 5->3->8->4->8->10->1->7->2->9->1->6->2\n",
      "Length of found path:  13\n",
      "Number of explored nodes:  145\n",
      "######\n",
      "A* with alpha = 4: \n",
      "Average time spent:  0.0016693274180094402\n",
      "Found path: 5->3->8->4->8->10->1->7->2->9->1->6->2\n",
      "Length of found path:  13\n",
      "Number of explored nodes:  135\n",
      "######\n"
     ]
    }
   ],
   "source": [
    "run_test(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST5: \n",
      "BFS: \n",
      "Average time spent:  0.10499803225199382\n",
      "Found path: 2->14->11->9->15->6->9->14->1->5->8->10->6->4->6->9->7\n",
      "Length of found path:  17\n",
      "Number of explored nodes:  4690\n",
      "######\n",
      "A*: \n",
      "Average time spent:  0.046333630879720054\n",
      "Found path: 2->14->11->9->15->6->9->14->1->5->8->10->6->4->6->9->7\n",
      "Length of found path:  17\n",
      "Number of explored nodes:  2605\n",
      "######\n",
      "A* with alpha = 2: \n",
      "Average time spent:  0.0066721439361572266\n",
      "Found path: 2->4->6->9->11->9->15->6->4->1->5->8->10->6->4->6->9->7\n",
      "Length of found path:  18\n",
      "Number of explored nodes:  565\n",
      "######\n",
      "A* with alpha = 4: \n",
      "Average time spent:  0.00966032346089681\n",
      "Found path: 2->14->11->9->15->6->9->14->1->5->8->10->6->4->6->9->7\n",
      "Length of found path:  17\n",
      "Number of explored nodes:  350\n",
      "######\n"
     ]
    }
   ],
   "source": [
    "run_test(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST6: \n",
      "BFS: \n",
      "Average time spent:  0.03266684214274088\n",
      "Found path: 11->6->5->10->7->10->5->1->2->9->14->6->8->4->2->1->3->7->13\n",
      "Length of found path:  19\n",
      "Number of explored nodes:  1843\n",
      "######\n",
      "A*: \n",
      "Average time spent:  0.029666344324747723\n",
      "Found path: 11->6->5->10->7->10->5->1->2->9->14->6->8->3->1->1->3->7->13\n",
      "Length of found path:  19\n",
      "Number of explored nodes:  1465\n",
      "######\n",
      "A* with alpha = 2: \n",
      "Average time spent:  0.005001942316691081\n",
      "Found path: 11->6->5->10->7->10->5->1->2->9->14->6->8->3->1->1->3->7->13\n",
      "Length of found path:  19\n",
      "Number of explored nodes:  315\n",
      "######\n",
      "A* with alpha = 4: \n",
      "Average time spent:  0.004997730255126953\n",
      "Found path: 11->6->5->10->7->9->14->6->5->10->5->1->2->1->3->7->13->7->3->8->3->1\n",
      "Length of found path:  22\n",
      "Number of explored nodes:  304\n",
      "######\n"
     ]
    }
   ],
   "source": [
    "run_test(6)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison and Conclusion\n",
    "BFS, IDS and A*(with consistent heuristic) always find the optimal path for us but weighted A* may not. But the advantage of weighted A* is its speed and memory. Because it visits less states, it needs less time and space to find a path that is at least near to an optimal path for us. With playing with $\\alpha$ constant we can find a proper value for it that has a good trade-off between optimality and speed. (in this problem $\\alpha = 2$ seems to work better) IDS is much slower than A* and BFS but its advantage is that it uses much less memory than other algorithms. IDS was not a good choice for this problem because we had too much state and since IDS save only its current path, it may visit some states more than once so it becomes too slow. In general for problems that have smaller space, we can use IDS. The disadvantage of A* in my opinion is that we have to find a good heuristic in order to make A* work well and it's not always an easy task. If our heuristic is not good enough, the algorithm's speed may become slower than BFS because it needs min-heap for its frontier queue."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources I Used for The Project:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [min-heap implementation](https://stackoverflow.com/questions/8875706/heapq-with-custom-compare-predicate)\n",
    "* [IDS algorithm](https://www.geeksforgeeks.org/iterative-deepening-searchids-iterative-deepening-depth-first-searchiddfs/)\n",
    "* [python typing](https://docs.python.org/3/library/typing.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
