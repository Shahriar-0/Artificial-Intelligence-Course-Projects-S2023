{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shahriar-0/Artificial-Intelligence-Course-Projects-S2023/blob/main/AI_CA6_P2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<html>\n",
        "<div>\n",
        "  <img src=\"https://www.engineersgarage.com/wp-content/uploads/2021/11/TCH36-01-scaled.jpg\" width=360px width=auto style=\"vertical-align: middle;\">\n",
        "  <span style=\"font-family: Georgia; font-size:30px; color: white;\"> <br/> University of Tehran <br/> AI_CA6_P2 <br/> Spring 02 </span>\n",
        "</div>\n",
        "<span style=\"font-family: Georgia; font-size:15pt; color: white; vertical-align: middle;\"> low_mist - std id: 810100186 </span>\n",
        "</html>\n",
        "\n",
        "In this notebook we are implement and train a Convolutional Neural Network to classify images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "# data manipulation\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from numpy.typing import NDArray\n",
        "from abc import ABC, abstractmethod\n",
        "import math\n",
        "\n",
        "# data visualization\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.axes import Axes\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plygdata as pg\n",
        "\n",
        "# sklearn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.datasets import make_moons, make_circles, make_classification\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    accuracy_score,\n",
        ")\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# types\n",
        "from dataclasses import dataclass\n",
        "from enum import Enum\n",
        "from typing import Union, Iterable, Callable, Optional\n",
        "from collections import namedtuple, Counter\n",
        "\n",
        "# tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import (\n",
        "    Dense,\n",
        "    Conv2D,\n",
        "    MaxPooling2D,\n",
        "    Dropout,\n",
        "    Activation,\n",
        "    Input,\n",
        "    Flatten,\n",
        "    BatchNormalization,\n",
        ")\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "\n",
        "\n",
        "## torch\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.nn import ReLU, Sigmoid, Linear\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch.autograd import grad\n",
        "\n",
        "# utils\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import difflib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cnn = Sequential()\n",
        "cnn.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=x_train.shape[1:]))\n",
        "cnn.add(Activation(\"relu\"))\n",
        "cnn.add(Conv2D(32, (3, 3)))\n",
        "cnn.add(Activation(\"relu\"))\n",
        "cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "cnn.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "cnn.add(Activation(\"relu\"))\n",
        "cnn.add(Conv2D(64, (3, 3)))\n",
        "cnn.add(Activation(\"relu\"))\n",
        "cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "cnn.add(Flatten())\n",
        "cnn.add(Dense(512))\n",
        "cnn.add(Activation(\"relu\"))\n",
        "cnn.add(Dense(10))\n",
        "cnn.add(Activation(\"softmax\"))\n",
        "cnn.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "log = cnn.fit(\n",
        "    x_train,\n",
        "    y_train_onehot,\n",
        "    batch_size=32,\n",
        "    epochs=20,\n",
        "    validation_data=(x_test, y_test_onehot),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.datasets import cifar10\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "# Normalize the pixel values:\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "# Convert the labels to one-hot encoding:\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\n",
        "# Split the data into training and testing sets:\n",
        "x_train, x_val, y_train, y_val = train_test_split(\n",
        "    x_train, y_train, test_size=0.2, random_state=42\n",
        ")\n",
        "# Verify the shapes of the data:\n",
        "print(\"Training data shape:\", x_train.shape)\n",
        "print(\"Validation data shape:\", x_val.shape)\n",
        "print(\"Testing data shape:\", x_test.shape)\n",
        "# Visualize the data:\n",
        "fig, axes = plt.subplots(nrows=5, ncols=5, figsize=(10, 10))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for i in np.arange(0, 25):\n",
        "    index = np.random.randint(0, len(x_train))\n",
        "    axes[i].imshow(x_train[index])\n",
        "    axes[i].set_title(y_train[index])\n",
        "    axes[i].axis(\"off\")\n",
        "\n",
        "plt.subplots_adjust(hspace=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "cnn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_cnn_model():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(64, (3, 3), padding=\"same\", input_shape=x_train.shape[:]))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(Conv2D(64, (3, 3)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(Conv2D(128, (3, 3)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(256, (3, 3), padding=\"same\"))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(Conv2D(256, (3, 3)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(10))\n",
        "    model.add(Activation(\"softmax\"))\n",
        "\n",
        "    model.compile(\n",
        "        loss=\"categorical_crossentropy\",\n",
        "        optimizer=Adam(lr=lr_schedule(0)),\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def lr_schedule(epoch):\n",
        "    lr = 1e-3\n",
        "    if epoch > 20:\n",
        "        lr *= 0.5e-3\n",
        "    elif epoch > 15:\n",
        "        lr *= 1e-3\n",
        "    elif epoch > 10:\n",
        "        lr *= 1e-2\n",
        "    elif epoch > 5:\n",
        "        lr *= 1e-1\n",
        "    print(\"Learning rate:\", lr)\n",
        "    return lr\n",
        "\n",
        "\n",
        "def fit_cnn_model(model: Sequential, x_train, y_train, x_test, y_test, batch_size=32, epochs=30):\n",
        "    log = model.fit(\n",
        "        x_train,\n",
        "        y_train,\n",
        "        batch_size=batch_size,\n",
        "        epochs=epochs,\n",
        "        validation_data=(x_test, y_test),\n",
        "        callbacks=[LearningRateScheduler(lr_schedule)],\n",
        "    )\n",
        "    return log\n",
        "\n",
        "\n",
        "model = create_cnn_model()\n",
        "log = fit_cnn_model(\n",
        "    model, x_train, y_train_onehot, x_test, y_test_onehot, batch_size=32, epochs=30\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyP8Ak0SXUbU2eMRKU0/xGRg",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
