{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "<div>\n",
    "  <img src=\"https://www.engineersgarage.com/wp-content/uploads/2021/11/TCH36-01-scaled.jpg\" width=360px width=auto style=\"vertical-align: middle;\">\n",
    "  <span style=\"font-family: Georgia; font-size:30px; color: white;\"> <br/> University of Tehran <br/> AI_CA1 <br/> Spring 02 </span>\n",
    "</div>\n",
    "<span style=\"font-family: Georgia; font-size:15pt; color: white; vertical-align: middle;\"> low_mist - std id: 810100186 </span>\n",
    "</html>\n",
    "\n",
    "In this notebook we are to solve a searching problem with different uninformed and informed search approaches and also compare their execution times. Approaches are:\n",
    "- Uninformed search algorithms, such as:\n",
    "    - BFS\n",
    "    - IDS\n",
    "- Informed search algorithms, such as:\n",
    "    - A*\n",
    "    - weighted A*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Description\n",
    "We have a Graph in which every node does either contain a student or pizza or it doesn't contain anything and it's just a normal node.  \n",
    "And each edge is either normal or is rickety which means if we cross it we have to wait at least a certain amount of time so it's safe again to cross. Each student has ordered a special pizza from special place and we have to go to each pizza station and get that pizza and deliver it, our goal is to find the shortest path with different search methods as mentioned.  \n",
    "There are some other constraints such as the priority in which some students are not allowed to get their pizza before some other and we also can carry one pizza at a time.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "## Graph and States\n",
    "first we have to define the graph components.  \n",
    "`Node`: contains the types plus it's edges.  \n",
    "`Edge`: contains destination the types plus it's unsafe time list if it's rickety (it's a list that shows if we have to wait for some seconds so it's safe again to cross)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import itertools\n",
    "from dataclasses import dataclass, field, fields, _MISSING_TYPE\n",
    "from typing import Any, Callable, Optional\n",
    "from enum import Flag, auto\n",
    "from collections import deque\n",
    "\n",
    "class EdgeType(Flag):\n",
    "    NORMAL = auto()\n",
    "    RICKETY = auto()\n",
    "\n",
    "@dataclass\n",
    "class Edge:\n",
    "    '''used for edge in graph, note that other than\n",
    "    usual information it has type and wait time (explained above) and weight'''\n",
    "    destination: int\n",
    "    id: int\n",
    "    type: EdgeType = field(default_factory = EdgeType.NORMAL)\n",
    "    wait_for: int = field(default_factory = 0)\n",
    "    weight: int = field(default_factory = 0)\n",
    "    \n",
    "class NodeType(Flag):\n",
    "    NORMAL = auto()\n",
    "    PIZZA = auto()\n",
    "    STUDENT = auto()\n",
    "\n",
    "@dataclass\n",
    "class Node:\n",
    "    '''used as node in graph, like edge it contains usual things plus \n",
    "    extra attribute which is type'''\n",
    "    edges: list[Edge]\n",
    "    type: NodeType"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have edges and nodes we define the graph that contains some extra information compared to normal graphs, namely, order of students, map from pizza to students and so forth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIRST_PRIORITY = 0\n",
    "SECOND_PRIORITY = 1\n",
    "\n",
    "class Graph:\n",
    "    '''this class is only the graph connection of problem not agent's state'''\n",
    "    def __init__(self, n : int):\n",
    "        self.num_of_nodes = n\n",
    "        self.nodes = [Node([], NodeType.NORMAL) for _ in range(n)]\n",
    "        self.pizzas_corresponding_students: dict[int, int] = dict()\n",
    "        self.priority_queues: list[tuple[int, int]] = list()\n",
    "        self.students: list[int] = list()\n",
    "        \n",
    "    def add_edges(self, origin: int, destination: int, type: EdgeType, id: int, wait_for: int = 0, weight: int = 0): \n",
    "        self.nodes[origin].edges.append(Edge(destination, id, type, wait_for, weight)) \n",
    "        self.nodes[destination].edges.append(Edge(origin, id, type, wait_for, weight))\n",
    "        \n",
    "    def add_pizza_and_student(self, student_position: int, pizza_position: int):\n",
    "        self.pizzas_corresponding_students[pizza_position] = student_position\n",
    "        self.students.append(student_position)\n",
    "        self.nodes[pizza_position].type = NodeType.PIZZA\n",
    "        self.nodes[student_position].type = NodeType.STUDENT\n",
    "        \n",
    "    def add_priority(self, priority: tuple[int, int]):\n",
    "        self.priority_queues.append((self.students[priority[FIRST_PRIORITY]], self.students[priority[SECOND_PRIORITY]]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to describe the states in which our agents will be during execution of search.  \n",
    "This ```AgentState``` class contains information about the world such as our position and left pizzas' locations and so forth, also about agent itself like the path it has taken to get here and such things.  \n",
    "The properties in our states are two types:  \n",
    "* criteria in determining uniqueness  \n",
    "    * `agent_position`: which shows the agent's position.  \n",
    "    <!-- * `left_pizzas`: which depicts the left pizzas position and their corresponding student positions. -->  \n",
    "    * `left_students`: which depicts the left students position and their corresponding pizza positions.  \n",
    "    <!-- * `time_elapsed`: the amount of time (in seconds) that has passed since we started the search.   -->\n",
    "    <!-- * `pizzas_carrying`: a dictionary containing the pizzas that we are carrying right now with their destination (note: it's said in problem that we can only carry one pizza at a time but we imagine that we can carry all of them and if we decide to deliver some pizza we will drop all other pizzas). -->  \n",
    "    * `remain_time_edges`: a map for keep tracking of time that we have to wait.\n",
    "    * `pizza_carrying`: the tuple which contains the pizza position and the student to whom we have to deliver the pizza. (if it exists)  \n",
    "* not important in determining uniqueness  \n",
    "    * `path`: which demonstrates the path we have taken to get here.  \n",
    "    <!-- * `satisfied_students`: which indicates the students are given their pizzas.   -->\n",
    "    * `priorities_left`: list of all priorities that are left and should be taken into account.  \n",
    "    <!-- * `pizzas_passed`: number of pizzas that we have passed -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass \n",
    "class AgentState:\n",
    "    agent_position: int\n",
    "    left_students: dict[int, int]\n",
    "    left_priorities: list[tuple[int, int]]\n",
    "    pizza_carrying : tuple[int, int] = field(default_factory = lambda: (None, None))\n",
    "    path: list[int] = field(default_factory = lambda: list())\n",
    "    remain_time_edges: dict[int, int] = field(default_factory = lambda: dict())\n",
    "    \n",
    "    def __tuple(self):\n",
    "        return (self.agent_position, tuple(self.left_students), tuple(self.remain_time_edges), self.pizza_carrying)\n",
    "    \n",
    "    def __eq__(self, other: Any) -> bool:\n",
    "        return (isinstance(other, AgentState)) and (\n",
    "            self.agent_position == other.agent_position and\n",
    "            self.left_students == other.left_students and\n",
    "            self.remain_time_edges == other.remain_time_edges and\n",
    "            self.pizza_carrying == other.pizza_carrying\n",
    "        )\n",
    "    \n",
    "    def __hash__(self) -> int:\n",
    "        return hash(self.__tuple)\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        return f\"{self.agent_position}, {self.pizza_carrying}, {self.remain_time_edges}, {self.left_students}\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define some useful functions for our agent.  \n",
    "- `has_reached_goad`: simply checks whether there is any pizza left or not.\n",
    "- `initial_state`: to create state which indicate where we are at start of the game.\n",
    "- `actions`: this function gets an state and returns the list of all actions that is available.\n",
    "\n",
    "**Note**: there are some optimization in the code each of them is explained or mentioned by comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy, copy\n",
    "STUDENT_INDEX = 1\n",
    "PIZZA_INDEX = 0\n",
    "\n",
    "\n",
    "class Agent:\n",
    "    @staticmethod\n",
    "    def has_reached_goal(state: AgentState) -> bool:\n",
    "        return len(state.left_students) == 0\n",
    "\n",
    "    @staticmethod\n",
    "    def initial_state(graph: Graph, start_position: int) -> AgentState:\n",
    "        return AgentState( \n",
    "            agent_position = start_position,\n",
    "            left_priorities = graph.priority_queues,\n",
    "            left_students = {value: key for key, value in graph.pizzas_corresponding_students.items()},\n",
    "            path = [start_position])  \n",
    "        \n",
    "        \n",
    "    @staticmethod\n",
    "    def has_seen_student(graph: Graph,position: int) -> bool:\n",
    "        return graph.nodes[position].type == NodeType.STUDENT\n",
    "\n",
    "    @staticmethod\n",
    "    def has_seen_pizza(graph: Graph,position: int) -> bool:\n",
    "        return graph.nodes[position].type == NodeType.PIZZA\n",
    "        \n",
    "    @staticmethod\n",
    "    def has_stayed(state: AgentState) -> bool:\n",
    "        return len(state.path) > 1 and state.path[-1] == state.path[-2]\n",
    "        \n",
    "    @staticmethod\n",
    "    def can_deliver_pizza(state: AgentState, position: int) -> bool:\n",
    "        pizza, student = state.pizza_carrying\n",
    "        return student in state.left_students and student == position\n",
    "    \n",
    "    @staticmethod\n",
    "    def deliver_pizza(state: AgentState):\n",
    "        pizza, student = state.pizza_carrying\n",
    "        del state.left_students[student]\n",
    "        state.left_priorities = list(filter(lambda x: x[FIRST_PRIORITY] != student, state.left_priorities))\n",
    "        state.pizza_carrying = (None, None)\n",
    "        \n",
    "    @staticmethod\n",
    "    def can_pick_pizza(state: AgentState, position: int, graph: Graph) -> bool:\n",
    "        student = graph.pizzas_corresponding_students[position]\n",
    "        return student in state.left_students and \\\n",
    "            not any(x[1] == student for x in state.left_priorities) and \\\n",
    "            state.pizza_carrying == (None, None)\n",
    "              \n",
    "    @staticmethod\n",
    "    def pick_pizza(ans: list[AgentState], state: AgentState, graph: Graph, position: int):\n",
    "        another_state = deepcopy(state)\n",
    "        another_state.pizza_carrying = (position, graph.pizzas_corresponding_students[position])\n",
    "        ans.append(another_state)\n",
    "    \n",
    "    @staticmethod\n",
    "    def actions(graph: Graph, state: AgentState) -> list[AgentState]:\n",
    "        ans : list[AgentState] = list()\n",
    "        \n",
    "        for edge in graph.nodes[state.agent_position].edges:\n",
    "            \n",
    "            if Agent.has_stayed(state) and edge.type != EdgeType.RICKETY:\n",
    "                continue    # cause if we have stayed then we want to cross one of the rickety edges\n",
    "            \n",
    "            new_state = deepcopy(state)\n",
    "            new_agent_position = edge.destination\n",
    "            new_state.remain_time_edges = {k: (v - 1) for k, v in new_state.remain_time_edges.items() if v >= 1}\n",
    "            \n",
    "            if edge.type == EdgeType.RICKETY:\n",
    "                if not edge.id in new_state.remain_time_edges:\n",
    "                    new_state.remain_time_edges[edge.id] = edge.wait_for # we cross the edge so we update the time \n",
    "                else:\n",
    "                    new_agent_position = state.agent_position # cause we won't move\n",
    "                \n",
    "            new_state.agent_position = new_agent_position\n",
    "            new_state.path.append(new_agent_position)\n",
    "            \n",
    "            if not Agent.has_stayed(new_state):      \n",
    "                      \n",
    "                if Agent.has_seen_student(graph, new_agent_position) and \\\n",
    "                Agent.can_deliver_pizza(new_state, new_agent_position):\n",
    "                    Agent.deliver_pizza(new_state)\n",
    "                \n",
    "                elif Agent.has_seen_pizza(graph, new_agent_position) and \\\n",
    "                    Agent.can_pick_pizza(new_state, new_agent_position, graph):\n",
    "                    Agent.pick_pizza(ans, new_state, graph, new_agent_position)\n",
    "                    \n",
    "            ans.append(new_state)\n",
    "            \n",
    "        return ans"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running algorithms\n",
    "We have all the fundamentals that are needed so it's time to read files and implement the searches.  \n",
    "**Note:** test files are in `assets\\Tests` directory.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "TIME_CUT_OFF = 20\n",
    "TYPE_INDEX = 2\n",
    "# every -1 is cause we start counting from 0\n",
    "\n",
    "def read_input_file(filename: str) -> tuple[Graph, int]:\n",
    "    with open(filename, 'r', encoding = 'utf-8') as file:\n",
    "        input = [line.rstrip('\\n') for line in file]\n",
    "    return read_input(input)\n",
    "    \n",
    "    \n",
    "def read_input(input: list[str]) -> Graph:\n",
    "    iterative_input = iter(input)\n",
    "    num_of_nodes, num_of_edges = map(int, next(iterative_input).split(\" \"))\n",
    "    graph = Graph(num_of_nodes)\n",
    "    \n",
    "    edges_line = []\n",
    "    for i in range(num_of_edges):\n",
    "        origin, destination = map(lambda x: int(x) - 1, next(iterative_input).split(\" \"))\n",
    "        edges_line.append([origin, destination, EdgeType.NORMAL, i])\n",
    "        \n",
    "    num_of_rickey_edges = int(next(iterative_input))\n",
    "    for i in range(num_of_rickey_edges):\n",
    "        num, time = map(int, next(iterative_input).split(\" \"))\n",
    "        edges_line[num - 1][TYPE_INDEX] = EdgeType.RICKETY\n",
    "        edges_line[num - 1].append(time)\n",
    "        \n",
    "    for edge in edges_line:\n",
    "        graph.add_edges(*edge)\n",
    "        \n",
    "    start_position = int(next(iterative_input)) - 1    \n",
    "        \n",
    "    num_of_students = int(next(iterative_input))\n",
    "    \n",
    "    for i in range(num_of_students):\n",
    "        student_node, pizza_node = map(lambda x: int(x) - 1, next(iterative_input).split(\" \"))\n",
    "        graph.add_pizza_and_student(student_node, pizza_node)\n",
    "        \n",
    "    num_of_priority = int(next(iterative_input))\n",
    "    for i in range(num_of_priority):\n",
    "        first, second = map(lambda x: int(x) - 1, next(iterative_input).split(\" \"))\n",
    "        graph.add_priority((first, second))\n",
    "        \n",
    "    return graph, start_position\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BFS\n",
    "We will search for the goal state with a *Breadth-First Search (BFS)* in state graph.  \n",
    "It's an uninformed search algorithm and explore states based on depth(time in this case)\n",
    "- advantages:\n",
    "    - complete\n",
    "    - optimal\n",
    "    - better exec-time than IDS\n",
    "- disadvantages:\n",
    "    - time and space complexity\n",
    "***\n",
    "- complexities:\n",
    "    - time complexity: $O(b^d)$\n",
    "    - space complexity: $O(b^d)$  \n",
    "    \n",
    "**Note**: `d`: depth of optimal solution.`b`: maximum branching factor.  \n",
    "***\n",
    "**Attention** :the goal check is done after the state is out of the queue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BFS(graph: Graph, start_position: int):    \n",
    "    start = Agent.initial_state(graph, start_position)\n",
    "    \n",
    "    if Agent.has_reached_goal(start):\n",
    "        return start\n",
    "    \n",
    "    frontier= []\n",
    "    visited = set()\n",
    "    frontier.append(start)\n",
    "    start = time()\n",
    "    finish = time() + TIME_CUT_OFF\n",
    "    while frontier and finish > start:\n",
    "        current_state = frontier.pop(0)\n",
    "        if Agent.has_reached_goal(current_state):\n",
    "            return current_state, len(visited)\n",
    "\n",
    "        for next_state in Agent.actions(graph, current_state):\n",
    "            if next_state in visited or next_state in frontier:\n",
    "                continue\n",
    "            frontier.append(next_state)\n",
    "\n",
    "        visited.add(current_state)\n",
    "        start = time()\n",
    "\n",
    "    return None, None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IDS\n",
    "It's an uninformed search algorithm and explore states using DFS approach with limited depth (increasing in each iteration)\n",
    "- advantages:\n",
    "    - complete\n",
    "    - optimal\n",
    "    - better space usage than DFS\n",
    "- disadvantages:\n",
    "    - time complexity\n",
    "***\n",
    "- complexities\n",
    "    - time complexity: $O(b^d)$\n",
    "    - space complexity: $O(b*d)$  \n",
    "    \n",
    "**Note**: `d`: depth of optimal solution.`b`: maximum branching factor.  \n",
    "\n",
    "***\n",
    "The following is an implementation of *iterative-deepening search (IDS)*.  \n",
    "IDS repeatedly uses *depth-limited search (DLS)* to run *depth-first search (DFS)* limited to a certain depth.  \n",
    "The depth increases by one every loop until the goal state is found.\n",
    "\n",
    "DLS is implemented recursively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def DLS(graph: Graph, start_position: int, depth_limit: int) -> tuple[AgentState, int]:\n",
    "    \n",
    "    def DLS_wrapped(graph: Graph, state: AgentState, visited_states: set[AgentState], depth_limit: int, number_of_visited_states: int = 0) -> tuple[AgentState, int]:\n",
    "        if depth_limit == 0:\n",
    "            return None, number_of_visited_states\n",
    "        \n",
    "        if Agent.has_reached_goal(state):\n",
    "            return state, number_of_visited_states\n",
    "        \n",
    "        for action in Agent.actions(graph, state):\n",
    "            if not action in visited_states:\n",
    "                visited_states.add(action)\n",
    "                number_of_visited_states += 1\n",
    "                ans, number_of_visited_states = DLS_wrapped(graph, action, visited_states, depth_limit - 1, number_of_visited_states)\n",
    "                visited_states.remove(action)\n",
    "\n",
    "                if ans is not None:\n",
    "                    return ans, number_of_visited_states\n",
    "                \n",
    "                \n",
    "        return None, number_of_visited_states\n",
    "    \n",
    "    \n",
    "    state = Agent.initial_state(graph, start_position)\n",
    "    visited_states : set[AgentState] = set()\n",
    "    visited_states.add(state)\n",
    "    return DLS_wrapped(graph, state, visited_states, depth_limit)\n",
    "\n",
    "def IDS(graph: Graph, start: int, depth_limit: int = 1e6):\n",
    "    start_time = time()\n",
    "    finish = time() + TIME_CUT_OFF\n",
    "    depth = 1\n",
    "    total_visited = 0\n",
    "    goal_state : AgentState = None\n",
    "    while goal_state is None and depth <= depth_limit and finish > start_time:\n",
    "        goal_state, currently_visited = DLS(graph, start, depth)\n",
    "        total_visited += currently_visited\n",
    "        depth += 1\n",
    "        start_time = time()\n",
    "    return goal_state, total_visited"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weighted A*\n",
    "\n",
    "It's an informed search algorithm and explore states using dijkstra approach.\n",
    "This algorithm tries to continue the search in a more targeted way by predicting the amount of cost from the current state to the goal state.\n",
    "\n",
    "This algorithm uses heuristics to predict the cost of continuing the route.\n",
    "\n",
    "- features:\n",
    "    - optimality: depends on heuristic\n",
    "        - admissible heuristic for tree search\n",
    "        - consistent heuristic for graph search\n",
    "\n",
    "    - complete\n",
    "\n",
    "- time complexity: number of node $f(n) <= C*$\n",
    "- space complexity: $exponential$\n",
    "\n",
    "\n",
    "    f(c): cost(n) + heuristic(n)\n",
    "\n",
    "To implement A* search we need a heuristic to estimate to cost to reach to a goal state.  \n",
    "The function I chose to use is defined as below:\n",
    "$$ heuristic(state) = 2 \\times (left\\space students) + (1\\space if\\space we\\space are\\space carrying\\space a\\space pizza)$$\n",
    "The logic behind it is so simple, we need to get to each pizza and deliver it and if we already have a pizza we have to deliver it to. So this is the minimum amount of cost left so our function is both ```admissible``` and ```consistent```.\n",
    "\n",
    "it is ```admissible```; because\n",
    "    for every state n, $h(n) <= h*(n)$\n",
    "and it won't over-estimate the cost to reach the goal.\n",
    "\n",
    "\n",
    "real cost is greater or equal to the cost implied by heuristic;\n",
    "\n",
    "so, it's ```consistent``` and\n",
    "    $real\\space cost(n_1 -> n_2) >= h(n_1) - h(n_2)$\n",
    "\n",
    "**attention**: $|h(n_1) - h(n_2)| <= 1$ and in each step, heuristic estimation can't change more than 1 unit.\n",
    "\n",
    "The A* search is basically BFS but instead of queue we have priority queue\n",
    "Weighted A* is just multiplying the heuristic value by ```alpha```. So for alpha=1, it is the same as A*.  \n",
    "Using an alpha value too high may not keep optimality. Because a consistent heuristic is always lower than the real cost, by multiplying it by an alpha, we hope to reach values closer to the real cost but this may break its consistency and therefore not return the optimal answer.  \n",
    "A* performs better than the previous algorithms in case of memory and time consumption. This is because it expands less states and is focused towards the goal state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bisect import bisect_left\n",
    "\n",
    "def AStar(graph: Graph, start_position: int, alpha: int = 1) -> tuple[AgentState, int]:\n",
    "    def insert(seq: list[AgentState], keys: list[int], item: AgentState, key: Callable[[AgentState], int] = lambda x: x):\n",
    "        '''Insert an item into a sorted list using a separate corresponding\n",
    "        sorted keys list and a key() to extract the key from each item.\n",
    "        Based on insert() method in SortedCollection recipe:\n",
    "        '''\n",
    "        k = key(item)  \n",
    "        i = bisect_left(keys, k)  \n",
    "        keys.insert(i, k)  \n",
    "        seq.insert(i, item) \n",
    "    \n",
    "    def h(state: AgentState) -> int:\n",
    "        '''this function only estimates the cost left'''\n",
    "        return 2 * len(state.left_students) + (1 if state.pizza_carrying[0] is not None else 0)\n",
    "    \n",
    "    def heuristic(state: AgentState) -> int:\n",
    "        '''this function is sum of what has been paid and what is likely to be paid'''\n",
    "        return alpha * h(state) + len(state.path)\n",
    "    \n",
    "    initial_state = Agent.initial_state(graph, start_position)\n",
    "    \n",
    "    frontier : list[int] = list()   # note that this list is priority queue and we insert in that based on that\n",
    "    visited : set[AgentState] = set()\n",
    "    frontier.append(initial_state)\n",
    "    keys: list[int] = list(map(heuristic, frontier))\n",
    "    start_time = time()\n",
    "    finish = time() + TIME_CUT_OFF\n",
    "    while frontier and start_time < finish:\n",
    "        new_state = frontier.pop(0)\n",
    "        if Agent.has_reached_goal(new_state):\n",
    "            return new_state, len(visited)\n",
    "        \n",
    "        for action in Agent.actions(graph, new_state):\n",
    "            if action in visited or action in frontier:\n",
    "                continue\n",
    "            insert(frontier, keys, action, heuristic)\n",
    "        \n",
    "        visited.add(new_state)\n",
    "        start_time = time()\n",
    "    \n",
    "    return None, None    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing \n",
    "Ok first we put test in a directory in order to run different algorithms.\n",
    "We will repeat them *TEST_REPEATS* times and calculate the average.  \n",
    "Each search algorithm will also return the goal state with number of states it has visited.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_REPEATS = 3\n",
    "\n",
    "def run(search_alg: Callable[[Graph, AgentState], tuple[AgentState, int]], filename: str):\n",
    "    graph, start_position = read_input_file(filename)\n",
    "    time_start = time()\n",
    "    for _ in range(TEST_REPEATS - 2):\n",
    "        goal_state, num_visited = search_alg(graph, start_position)\n",
    "    time_elapsed = (time() - time_start) / TEST_REPEATS\n",
    "\n",
    "    if goal_state is None:\n",
    "        print('No solution')\n",
    "    else:\n",
    "        print(*[x + 1 for x in goal_state.path], sep = '->')\n",
    "        print('Path cost:', len(goal_state.path) - 1)\n",
    "        print('Visited states:', num_visited)\n",
    "        print('Average time:', time_elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      " **  Test Number 0  ** \n",
      "---------------BFS-------------------\n",
      "1->2->3->4->4->4->3->2->3->5\n",
      "Path cost: 9\n",
      "Visited states: 89\n",
      "Average time: 0.0018420219421386719\n",
      "---------------IDS-------------------\n",
      "1->2->3->4->4->4->3->2->3->5\n",
      "Path cost: 9\n",
      "Visited states: 2123\n",
      "Average time: 0.03389056523640951\n",
      "---------------A*-------------------\n",
      "1->2->3->4->4->4->3->2->3->5\n",
      "Path cost: 9\n",
      "Visited states: 67\n",
      "Average time: 0.0037769476572672525\n",
      "---------------A* alpha = 2-------------------\n",
      "1->2->3->4->4->4->3->2->3->5\n",
      "Path cost: 9\n",
      "Visited states: 42\n",
      "Average time: 0.0015048980712890625\n",
      "---------------A* alpha = 4-------------------\n",
      "1->2->3->4->4->4->3->2->3->5\n",
      "Path cost: 9\n",
      "Visited states: 36\n",
      "Average time: 0.0016667842864990234\n",
      "---------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------\n",
      " **  Test Number 1  ** \n",
      "---------------BFS-------------------\n",
      "6->4->10->5->3->8->9->1->7->9->2\n",
      "Path cost: 10\n",
      "Visited states: 7031\n",
      "Average time: 2.28221329053243\n",
      "---------------IDS-------------------\n",
      "No solution\n",
      "---------------A*-------------------\n",
      "6->4->10->9->1->3->8->9->7->9->2\n",
      "Path cost: 10\n",
      "Visited states: 660\n",
      "Average time: 0.15722950299580893\n",
      "---------------A* alpha = 2-------------------\n",
      "6->4->10->9->1->3->8->9->7->9->2\n",
      "Path cost: 10\n",
      "Visited states: 220\n",
      "Average time: 0.02674380938212077\n",
      "---------------A* alpha = 4-------------------\n",
      "6->4->10->9->1->3->8->9->7->9->2\n",
      "Path cost: 10\n",
      "Visited states: 89\n",
      "Average time: 0.010276317596435547\n",
      "---------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------\n",
      " **  Test Number 2  ** \n",
      "---------------BFS-------------------\n",
      "No solution\n",
      "---------------IDS-------------------\n",
      "No solution\n",
      "---------------A*-------------------\n",
      "No solution\n",
      "---------------A* alpha = 2-------------------\n",
      "No solution\n",
      "---------------A* alpha = 4-------------------\n",
      "14->9->4->15->12->3->8->6->8->6->4->9->14->1->14->12->6->8->11->5->3->13\n",
      "Path cost: 21\n",
      "Visited states: 6335\n",
      "Average time: 4.865039745966594\n",
      "---------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------\n",
      " **  Test Number 3  ** \n",
      "---------------BFS-------------------\n",
      "No solution\n",
      "---------------IDS-------------------\n",
      "No solution\n",
      "---------------A*-------------------\n",
      "No solution\n",
      "---------------A* alpha = 2-------------------\n",
      "No solution\n",
      "---------------A* alpha = 4-------------------\n",
      "No solution\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "search_algorithms ={\"BFS\": BFS, \"IDS\": IDS, \"A*\": partial(AStar, alpha = 1), \"A* alpha = 2\": partial(AStar, alpha = 2), \"A* alpha = 4\": partial(AStar, alpha = 4) }\n",
    "\n",
    "NUMBER_OF_TESTS = 4\n",
    "\n",
    "for i in range(NUMBER_OF_TESTS):\n",
    "    print(\"---------------------------------------------------------------------------\")\n",
    "    print(f\" **  Test Number {i}  ** \")\n",
    "    for search_algorithm in search_algorithms:\n",
    "        print(f\"---------------{search_algorithm}-------------------\")\n",
    "        algorithm_function = search_algorithms[search_algorithm]\n",
    "        run(algorithm_function, f\"assets\\Tests\\Test{i}.txt\")\n",
    "    print(\"---------------------------------------------------------------------------\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input_0.txt:\n",
    "\n",
    "| Algorithm | Cost | Visited States | Run Time |                       Path                          |                            \n",
    "| :-: | :--: | :------------: | :------: |  :------------------------------------------------: |                          \n",
    "| BFS | 9    | 89             | 0.0020   |              1->2->3->4->4->4->3->2->3->5           |  \n",
    "| IDS | 9    | 2123           | 0.0186   |              1->2->3->4->4->4->3->2->3->5           |  \n",
    "| A*  | 9    | 67             | 0.0011   |              1->2->3->4->4->4->3->2->3->5           |  \n",
    "| A* Alpha=1.2 | 9 | 42       | 0.0006   |              1->2->3->4->4->4->3->2->3->5           |  \n",
    "| A* Alpha=5   | 9 | 36       | 0.0011   |              1->2->3->4->4->4->3->2->3->5           |  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input_1.txt:\n",
    "\n",
    "| Algorithm | Cost | Visited States | Run Time |                       Path                        |                            \n",
    "| :-: | :--: | :------------: | :------: |  :------------------------------------------------: |                          \n",
    "| BFS | 10    | 7031             | 1.9673   |              6->4->10->5->3->8->9->1->7->9->2           |  \n",
    "| IDS | -    | -           | -   |              -          |  \n",
    "| A*  | 10    | 660             | 0.0856   |              6->4->10->9->1->3->8->9->7->9->2           |  \n",
    "| A* Alpha=1.2 | 10 | 220| 0.0194   |              6->4->10->9->1->3->8->9->7->9->2           |  \n",
    "| A* Alpha=5   | 10 | 89       | 0.0047   |              6->4->10->9->1->3->8->9->7->9->2           |  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "BFS and IDS will always give us the optimal solution.  \n",
    "A* with a consistent heuristic will also give the optimal solution.  \n",
    "But weighted A* may not always give us the optimal solution, but if it does, it is faster than the rest of the algorithms.\n",
    "\n",
    "As a general speed comparison: Weighted A* > A* > BFS > IDS  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
